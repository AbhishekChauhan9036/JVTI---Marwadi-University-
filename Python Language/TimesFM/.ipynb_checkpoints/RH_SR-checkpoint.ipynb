{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fab69cad-8dee-4c02-a3bc-f9531f8b4a22",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_name_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults saved for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Main function to load data, test, and evaluate the model\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _name_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_main_\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# Define the output directory for results\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:/Q/RESULTS\u001b[39m\u001b[38;5;124m\"\u001b[39m   \u001b[38;5;66;03m# Directory to store results\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name '_name_' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "\n",
    "# Additional metric for MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Load and preprocess the air pollution data\n",
    "def load_and_preprocess_data(file_path, target_feature):\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Correct the date format using dayfirst=True\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%d-%m-%Y %H:%M', dayfirst=True, errors='coerce')\n",
    "\n",
    "    # Drop rows with invalid or missing date values\n",
    "    data = data.dropna(subset=['Date'])\n",
    "\n",
    "    # Set the 'Date' column as the index\n",
    "    features = data.copy()\n",
    "    features.set_index('Date', inplace=True)\n",
    "\n",
    "    # Ensure the target feature exists\n",
    "    if target_feature not in features.columns:\n",
    "        raise ValueError(f\"Target column '{target_feature}' not found in the dataset.\")\n",
    "\n",
    "    # Extract all feature columns except the target\n",
    "    feature_columns = features.columns \n",
    "\n",
    "    # Scale the data\n",
    "    feature_scaler = MinMaxScaler()\n",
    "    target_scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit and transform the feature data\n",
    "    features_scaled = feature_scaler.fit_transform(features[feature_columns])\n",
    "\n",
    "    # Fit and transform the target data\n",
    "    target_scaled = target_scaler.fit_transform(features[[target_feature]])\n",
    "\n",
    "    return features_scaled, target_scaled, feature_scaler, target_scaler\n",
    "\n",
    "# Prepare the dataset for the model input (general structure for time series)\n",
    "def create_dataset(features, target, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(features) - seq_length):\n",
    "        X.append(features[i:i+seq_length].flatten())\n",
    "        y.append(target[i+seq_length])\n",
    "\n",
    "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Placeholder for TimeGPT model (replace with actual TimeGPT model or API call)\n",
    "class TimeGPTModel:\n",
    "    def _init_(self, input_size):\n",
    "        # Simulate a model that doesn't have trainable parameters\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Simulate the TimeGPT prediction logic here (replace with actual API call or model inference)\n",
    "        return X.mean(dim=1, keepdim=True)  # Dummy prediction logic, replace with real inference\n",
    "\n",
    "# Testing the model (no training)\n",
    "def test_model(model, X_test, target_scaler):\n",
    "    with torch.no_grad():\n",
    "        # Simulating TimeGPT predictions\n",
    "        predictions = model.predict(X_test).squeeze()\n",
    "\n",
    "        # Ensure non-negative predictions\n",
    "        predictions = torch.relu(predictions).numpy()\n",
    "\n",
    "        # Rescale predictions back to original scale\n",
    "        predictions_rescaled = target_scaler.inverse_transform(predictions.reshape(-1, 1))\n",
    "\n",
    "        return predictions_rescaled\n",
    "\n",
    "# Evaluate model and store results\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return mse, rmse, mae, mape, r2\n",
    "\n",
    "# Save results to CSV\n",
    "def save_results(predictions, actual_values, feature_name, output_dir):\n",
    "    results = pd.DataFrame({\n",
    "        \"Predictions\": predictions.flatten(),\n",
    "        \"Actual\": actual_values.flatten()\n",
    "    })\n",
    "    results.to_csv(os.path.join(output_dir, f\"{feature_name}_predictions.csv\"), index=False)\n",
    "    print(f\"Results saved for {feature_name}\")\n",
    "\n",
    "# Main function to load data, test, and evaluate the model\n",
    "if _name_ == \"_main_\":\n",
    "    # Define the output directory for results\n",
    "    output_dir = r\"E:/Q/RESULTS\"   # Directory to store results\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load and preprocess data\n",
    "    file_path = r\"C:\\Users\\SPURGE\\Desktop\\JVTI\\Python Language\\TimesFM/pm_sr.csv\"  # Update file path for multivariate data\n",
    "    target_features = ['PM2.5', 'PM10', 'RH', 'SR']  # List of all features to predict\n",
    "\n",
    "    seq_length = 12  # Example sequence length\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for target_feature in target_features:\n",
    "        print(f\"Evaluating TimeGPT model for target: {target_feature}\")\n",
    "\n",
    "        features_scaled, target_scaled, feature_scaler, target_scaler = load_and_preprocess_data(file_path, target_feature)\n",
    "\n",
    "        # Prepare dataset\n",
    "        X, y = create_dataset(features_scaled, target_scaled, seq_length)\n",
    "\n",
    "        # Split data into training, validation, and test sets\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 50% of remaining 30% for val/test\n",
    "\n",
    "        # Initialize TimeGPT model (replace with actual model or API call)\n",
    "        input_size = X_train.shape[1]\n",
    "        model = TimeGPTModel(input_size)\n",
    "\n",
    "        # Test the model directly (no training)\n",
    "        predictions = test_model(model, X_test, target_scaler)\n",
    "\n",
    "        # Rescale actual values back to original scale\n",
    "        y_test_rescaled = target_scaler.inverse_transform(y_test.numpy().reshape(-1, 1))\n",
    "\n",
    "        # Save predictions and actual values to CSV\n",
    "        save_results(predictions, y_test_rescaled, target_feature, output_dir)\n",
    "\n",
    "        # Evaluate the model\n",
    "        mse, rmse, mae, mape, r2 = evaluate_model(y_test_rescaled, predictions)\n",
    "\n",
    "        # Append results\n",
    "        results.append({\n",
    "            'Target Feature': target_feature,\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'MAPE': mape,\n",
    "            'R2': r2\n",
    "        })\n",
    "\n",
    "    # Save overall evaluation results to CSV\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(os.path.join(output_dir, f\"{target_feature}_predictions_eval.csv\"), index=False)\n",
    "\n",
    "        print(\"Evaluation results saved to 'model_evaluation_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fad04132-02c9-4975-81d3-ff5c794e3a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2399c743-c559-4465-b399-25610d4bf36b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
